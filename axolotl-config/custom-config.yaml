base_model: Qwen/Qwen2.5-7B-Instruct
tokenizer_type: AutoTokenizer

datasets:
  - path: timdettmers/openassistant-guanaco
    type: completion
    field: text
    
load_in_4bit: true
adapter: qlora

sequence_len: 2048
micro_batch_size: 1
gradient_accumulation_steps: 8
num_epochs: 1

learning_rate: 2e-4
optimizer: paged_adamw_8bit
lr_scheduler: cosine

fp16: true
gradient_checkpointing: true

output_dir: /workspace/my_runs/output_sft
logging_steps: 10
save_steps: 500
