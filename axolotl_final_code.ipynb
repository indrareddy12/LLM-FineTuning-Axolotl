{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_I-VSFAgmRW"
   },
   "source": [
    "## “The goal of this practical is very clear:\n",
    "minimum steps, maximum clarity.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qTeCCThGoPrZ",
    "outputId": "a2e4a04b-8806-489f-c208-289d50523c1c"
   },
   "outputs": [],
   "source": [
    "!pip uninstall -y axolotl peft transformers accelerate datasets trl optimum cut-cross-entropy flash-attn\n",
    "!pip install --no-build-isolation git+https://github.com/OpenAccess-AI-Collective/axolotl.git\n",
    "!pip install --no-build-isolation axolotl[flash-attn]>=0.9.1\n",
    "!pip install \"cut-cross-entropy[transformers] @ git+https://github.com/axolotl-ai-cloud/ml-cross-entropy.git@318b7e2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e8Xp8jM3jQwc"
   },
   "outputs": [],
   "source": [
    "dataset_id = \"winglian/pirate-ultrachat-10k\"\n",
    "uploaded = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o7pZxanqkL9w"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "GOOGLE_DRIVE_PATH = \"\"\n",
    "if GOOGLE_DRIVE_PATH:\n",
    "    from google.colab import drive\n",
    "    GOOGLE_DRIVE_MNT = \"/content/drive/\"\n",
    "    drive.mount(GOOGLE_DRIVE_MNT, force_remount=True)\n",
    "    tmp_path = os.path.join(GOOGLE_DRIVE_MNT, GOOGLE_DRIVE_PATH.lstrip(\"/\"))\n",
    "    if not os.path.isfile(tmp_path):\n",
    "        raise ValueError(f\"File {tmp_path} does not exist\")\n",
    "    dataset_id = tmp_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e1D5KRJWk5Zw"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"AXOLOTL_DO_NOT_TRACK\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NlxEg5x8xrvH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NdPeJcszk-dO"
   },
   "outputs": [],
   "source": [
    "from axolotl.cli.config import load_cfg\n",
    "from axolotl.utils.dict import DictDefault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "7ef9e06ded77426fba5f7eafa4508b31",
      "dc507e90d4fb4246882bb981bc922111",
      "766d53eb54694263864998c46678416a",
      "7a73976032844d66ad3bac06dd5617dd",
      "46e36b18a4b2401b8264c60c86cf2044",
      "ebb963c77b604af1a2d883820440c71e",
      "9663189e68fc4c6aac12cd5e1b9128bf",
      "c56839f40bca4663a40498487e451b08",
      "9325b4ed54434838a80841cd7d08366d",
      "0eb19b509884496d8426661d9c9c1e7d",
      "44455d73f2a743ecbcac85b908c2869f"
     ]
    },
    "id": "CbKM_iV3kU6J",
    "outputId": "561be2f1-f443-4bba-f22c-81408147a29d"
   },
   "outputs": [],
   "source": [
    "config = DictDefault(\n",
    "    base_model=\"Qwen/Qwen2.5-3B-Instruct\",\n",
    "    load_in_4bit=True,\n",
    "    adapter=\"qlora\",\n",
    "    lora_r=32,\n",
    "    lora_alpha=64,\n",
    "    lora_target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"down_proj\",\n",
    "        \"up_proj\",\n",
    "    ],\n",
    "    lora_qkv_kernel=False,\n",
    "    lora_o_kernel=False,\n",
    "    lora_mlp_kernel=False,\n",
    "    embeddings_skip_upcast=True,\n",
    "    xformers_attention=True,\n",
    "    plugins=[],\n",
    "    sample_packing=False,\n",
    "    learning_rate=0.00019,\n",
    "    sequence_len=1024,\n",
    "    micro_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\n",
    "        \"use_reentrant\": False,\n",
    "    },\n",
    "    optimizer=\"paged_adamw_8bit\",\n",
    "    lr_scheduler=\"cosine\",\n",
    "    warmup_steps=5,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.1,\n",
    "    num_epochs=1,\n",
    "    saves_per_epoch=2,\n",
    "    logging_steps=1,\n",
    "    output_dir=\"./outputs/qwen-sft-pirate-rrr\",\n",
    "    chat_template=\"qwen3\",\n",
    "    datasets=[\n",
    "        {\n",
    "            \"path\": dataset_id,\n",
    "            \"type\": \"chat_template\",\n",
    "            \"split\": \"train\",\n",
    "            \"eot_tokens\": [\"<|im_end|>\"],\n",
    "        }\n",
    "    ],\n",
    "    dataloader_prefetch_factor=2,\n",
    "    dataloader_num_workers=0,\n",
    "    dataloader_pin_memory=True,\n",
    ")\n",
    "cfg = load_cfg(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c1ulKwO6kuJN"
   },
   "outputs": [],
   "source": [
    "from axolotl.utils import set_pytorch_cuda_alloc_conf\n",
    "set_pytorch_cuda_alloc_conf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "3b611f43c7c84aa7831d76f760ea401c",
      "b266aac7f7de4212b40a5794d719b1b2",
      "d8afccf52ef64f1da162e137ca733e81",
      "ebac332bc0be4ec493bfb24370d39d22",
      "e578dca7ef054315886d2bd47d8cd44b",
      "ef40939ab27042a199b9798ae9a4ded8",
      "01db31742f034bf6867425cebea671fe",
      "c84ed9321dbc4123881220cb342d59b0",
      "e889b2fca5fc4f6ab1680cbcbedd3082",
      "ab55634dcb964a4a8ce2fd7c39e051c0",
      "e00bdf65070a4f449776c008fb5a478f",
      "ebd9c6a046bc47b58c6d8d48c877b876",
      "c3ee42492bc64770b64ebfbc04e6143a",
      "01d3f4a61cb9406e81b163f2898a2290",
      "7f755370c3fb4bc9be8112974fef1fd0",
      "28469c0e69764f3ba60a39a8f9508a05",
      "de2f04bc59e24652a8b1153e1a3ba31c",
      "dc62425897f44cd79ca59ee57875db90",
      "66acad22188644eab6a6c323c420a4b1",
      "2994f494fa014ded8d6138e6673178a7",
      "0a5bfb4af65941d499c4dd7b489b92f8",
      "efe3a0a995454e04a624cb4625bf3af7",
      "830a178a73754de6b0c664309537021f",
      "37390e463fb547cd8e2c66a9a4978c2f",
      "5cba793413b441c0b7368364d71d040a",
      "c0d26972ac154cd3aa0eb3c4796cd375",
      "d44ddb7e6e424c4899da7e2e6037d684",
      "8a53675faf4e4a07a385b4414e3722ee",
      "ad6a0fdebc9840caa0f20d1d5bb85930",
      "8ca5767c57c44c7e93bdb74e5232b177",
      "77a895a77d064d2981acacbf5d88c6b3",
      "9cee5c83006c41d989bb8497d67f0745",
      "ae098ae2b7a5445a95f90d93a0af6a44",
      "505278af2d4d415992d75e54f92efa45",
      "f623a7a267ab47ec9fb59ead907d5b7d",
      "37faad59729b4a2085feda260d71a24a",
      "a3adcdb997ca432db778ce69b364650c",
      "094f47b3b0d542ba864b9b2ccde48305",
      "fdf8c8cc946443f3b77d038ea5d0bf18",
      "5fdd1056cd634f2babbfd6ca4c935e73",
      "790017f9043b467785ddce1ea3ada8c1",
      "eeb6c327d39848f5bacdd794bbdd75de",
      "ac458b425a234df5b35bda9f482dfa80",
      "aa7391311163410b9637990eb856488a",
      "a778e55862cd4180a78e971a7d9fb4dd",
      "fbafb40a939f4dcf8d54bdadbc4a2f7b",
      "deebc7e05aba4829aa2abd95f1276978",
      "68950e09b7ad4bb8be4849f45dea96ce",
      "a360920ba8b74fb993170a6243b20b32",
      "05b81f987a3d41a3a28d5d73781be98a",
      "da1a7bdb9dbc49f8939b66770cf2372c",
      "05fad1274f3c47d787083785851aaf62",
      "2b78661ec3d54013915cd5be30cc6cc9",
      "eb12d53ac94249d6919786f04ec66443",
      "2ff2afa10f224dd49ee4b1248dfc3c70",
      "e8afe06d7fcd40079338477be96ae64e",
      "0ea660a0ccca41a3b2baff6948db7325",
      "b88e3ea9ee124fc2a8009a8db1e99945",
      "487cbf01c62340fd900b9b2ad48285fe",
      "d53500bf7b194207a3984fd5f8963e0d",
      "38218dfc64ae4478ae3ace676e6c0436",
      "38e2ec057b7a400faa9bc3c2c7e6124e",
      "f30449b889ff48ea8aa75bb6451879a9",
      "7ce4ae26d1c9481bbd20274bbdb9a834",
      "8d5fc1a08835490c8ec8d5bf815920c7",
      "b16d09650da54275940a5701ae123a38",
      "47990a9d9d664e759b34e1eb85116f77",
      "007cde459998431b9281d1e166c9d76e",
      "6e92181115a84a4c9c51592a9fc5b19f",
      "9a728c9f3d6a4730a2c4e1e8e2e0338f",
      "0d9e38fe8a984812b770c615ab0f6797",
      "cfa5737fb7104ca7ba7e96ede933664a",
      "89fef778a2a145459e7016c706029d81",
      "36fc7fcdc9604968a6fde96aed1433b8",
      "5938d775b8a641d8a55fe89b887600e2",
      "931c206d6c504e0bb4e1ec98d38f2f6b",
      "110745026d8c4bd19d62fec5c0318cd0"
     ]
    },
    "id": "FbKb-b9Xro7O",
    "outputId": "eb276a97-0e80-4bc4-f950-d741bddae946"
   },
   "outputs": [],
   "source": [
    "from axolotl.common.datasets import load_datasets\n",
    "dataset_meta = load_datasets(cfg=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547,
     "referenced_widgets": [
      "d5abd804a0dc4c73a4ce7396c50238de",
      "9ebf5fe776f44b07b81c8f3ae38b4b1a",
      "38d7aedd1d384a81aa3aed8ba50746ea",
      "0ad0407839b248e38c68673505fcf597",
      "6111c56ea4244add90f159fa4f46789f",
      "232801eceeed4dcc9e423865a9db9ad4",
      "b5dd0b0affe74ccc888e54f19875d342",
      "c3e2086f73014648a5a19d4f14fd0eaf",
      "27cdb85a06d04960a10751ee57afea48",
      "428c24ccec0e48bdb9ba680ad560e2c5",
      "b0d178f106d3480790ad7b6251409eb7",
      "0ef8badcc45e403ba677d4a171aea64d",
      "bd662d980ddf4b7b836911bafc0b05a5",
      "949770b77d79498fba7d15bc88d72f21",
      "434a0d8e50334c5da31e48dad2ddfaf3",
      "aec5377f7735467bbc2ebe929da912e9",
      "7f8706bc903549089ce6f1c314773b0c",
      "ffe0a0c1419146988661334a22b2d192",
      "c32bf69902ba40649e95356d044b92b2",
      "bc86fe579b3a4d90a14db9a76c447c95",
      "4f10d0a381cb4560a5e13c040bef057b",
      "78135cde2c3c4b4f8c0d084a76ac8c03",
      "24e9adc498c9483fa04c605a1b70a336",
      "ffcb33506ec64e8a8847211736091cfb",
      "b9ff3fe4bcbe44e2b7c67bdd332f61eb",
      "a3c3bf0392f542518ab6009b05c0e233",
      "c870bba990f14f23a678afa3d8cbfda4",
      "5dfca8f3a8dc4feb9dba16a47125a33f",
      "9a0698de0f8342ecb7228720ecc31fc8",
      "e419733360ba4dc4a07abf828a618549",
      "0f38db8f66894e768c63ae483effc189",
      "bcf6d5e997b24e3a85043ef877de5f6c",
      "51d471f1d1454abf89a48197f09632ea",
      "89238789e5d548199e75736cf8c940e8",
      "98c3cc1c49a1453da0ab1858634c84c6",
      "99ef65dad60949d79a3cf49feb914cd0",
      "243cc5591d094d50822ffe3a6c538be5",
      "5e8a030207e149bfb14c8370a84aa4d7",
      "2775f4630bb84c73b6b84c2076dfb126",
      "81a3a96be68c49c18cec9cc32d0121e4",
      "25e9418e7b094afd809f435fc81d0ba7",
      "d57455d986704e8193c331f85a985419",
      "7cfc349e84cb48f8801b68b9a2fbf71a",
      "c95cf11f1d154cd5990cedffc94fc0ab",
      "4cbc8f58429843a89426520c3a7ae9c9",
      "e8dccbc7502d46ee85f37d48884a4ab8",
      "19f38efadefa4965ade02d39c417775d",
      "817fd87846af4323b72017f38959db12",
      "45d361c900be4e1d953f371e8ff704cc",
      "a6319c5ae2b640b79eae1c0ec68b3f03",
      "7d957c6ad89344ef8e4f7e07202e9a9d",
      "74d714a0bf9f4967807bcd976637c48c",
      "2ae1960984484ee6ba9515b77566277f",
      "ee826761fa6d4047bd0d82d3887b2785",
      "0630c042939a4682a75b06d8fba2389f"
     ]
    },
    "id": "M4ud8vSprsSn",
    "outputId": "be2146d6-000b-4a25-bdee-c738424bcd1a"
   },
   "outputs": [],
   "source": [
    "from axolotl.train import train\n",
    "cfg.max_steps = 25\n",
    "model, tokenizer, trainer = train(cfg=cfg, dataset_meta=dataset_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgLGWIplsDPA"
   },
   "outputs": [],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Explain the Pythagorean theorem to me.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=False,\n",
    "    enable_thinking=False,\n",
    ")\n",
    "\n",
    "outputs = model.generate(\n",
    "    **tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\"),\n",
    "    max_new_tokens=192,\n",
    "    temperature=1.0,\n",
    "    top_p=0.8,\n",
    "    top_k=32,\n",
    "    streamer=TextStreamer(tokenizer, skip_prompt=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Us5gIKcRdASz"
   },
   "outputs": [],
   "source": [
    "# Show the saved checkpoints in the output_dir\n",
    "!ls -lh \"./outputs/qwen-sft-pirate-rrr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4sGOl0CDdAtq"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "# remove the partial epoch checkpoints\n",
    "!rm -rf \"./outputs/qwen-sft-pirate-rrr/checkpoint-*\"\n",
    "\n",
    "# HF Notebook login widget\n",
    "notebook_login()\n",
    "\n",
    "# upload the LoRA adapter for your model to HF, remember to update the username/model-name below\n",
    "!huggingface-cli upload --repo-type=model winglian/pirate-qwen-14B \"./outputs/qwen-sft-pirate-rrr\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
